{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is Part 1 of LinkedIn Posts scrapping. In this notebook Selenium + Python has been used. This code extracts the posts from LinkedIn based on given keywords. While running this notebook, you need to provide LinkedIn link generated by searching a word on LinkedIn after running first cell. After running second cell, you need to provide your LinkedIn Id & pass. Please also note that this code is for Windows system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required installs (i.e. pip3 install in terminal): pandas, selenium, bs4\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import random\n",
    "#import caffeine\n",
    "#caffeine.on(display=True)\n",
    "\n",
    "page = input(\"Enter the Company Linkedin URL: \")\n",
    "company_name = page[33:-1]\n",
    "\n",
    "try:\n",
    "    f= open(\"credentials.txt\",\"r\")\n",
    "    contents = f.read()\n",
    "    username = contents.replace(\"=\",\",\").split(\",\")[1]\n",
    "    password = contents.replace(\"=\",\",\").split(\",\")[3]\n",
    "except:\n",
    "    f= open(\"credentials.txt\",\"w+\")\n",
    "    username = input('Enter your linkedin username: ')\n",
    "    password = input('Enter your linkedin password: ')\n",
    "    f.write(\"username={}, password={}\".format(username,password))\n",
    "    f.close()\n",
    "\n",
    "# Output after running this code block - \"Enter the Company Linkedin URL:\" - Paste this URL (https://www.linkedin.com/search/results/content/?keywords=stalk&origin=SWITCH_SEARCH_VERTICAL)\n",
    "#                                                                            in the box and press Enter\n",
    "# You will also get same URL if you login to your LinkedIn and give 'stalk' in search bar of LinkedIn and select Posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access Webriver\n",
    "#browser = webdriver.Chrome('chromedriver')\n",
    "browser = webdriver.Chrome(r'C:\\Users\\sanni\\Downloads\\applications\\chromedriver_win32\\chromedriver')\n",
    "\n",
    "#Open login page\n",
    "browser.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')\n",
    "\n",
    "#Enter login info:\n",
    "elementID = browser.find_element_by_id('username')\n",
    "elementID.send_keys(username)\n",
    "\n",
    "elementID = browser.find_element_by_id('password')\n",
    "elementID.send_keys(password)\n",
    "#Note: replace the keys \"username\" and \"password\" with your LinkedIn login info. Please provide the Username & Password in quotes('')\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Go to webpage\n",
    "browser.get(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll():\n",
    "    #Simulate scrolling to capture all posts\n",
    "    SCROLL_PAUSE_TIME = random.randint(1,3)\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    #print(last_height)\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_up():\n",
    "    #Simulate scrolling to capture all posts\n",
    "    SCROLL_PAUSE_TIME = random.randint(1,3)\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(document.body.scrollHeight, 0);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_post(container):\n",
    "    \n",
    "        global post_dates \n",
    "        global post_texts \n",
    "        global post_likes\n",
    "        global post_comments\n",
    "        global video_views \n",
    "        global media_links \n",
    "        global media_type \n",
    "    \n",
    "        try:\n",
    "            try:\n",
    "                post_date = container.find(\"span\",{\"class\":\"feed-shared-actor__sub-description t-12 t-normal t-black--light\"}) \n",
    "                post_dates.append(post_date.text.strip()[0:-2])\n",
    "            except:\n",
    "                post_dates.append(\"None\")\n",
    "                \n",
    "            try:\n",
    "                text_box = container.find(\"div\",{\"class\":\"feed-shared-update-v2__description-wrapper ember-view\"})   \n",
    "                post_texts.append(text_box.text.strip())\n",
    "            \n",
    "            except:\n",
    "                post_texts.append(\"None\")\n",
    "            \n",
    "            try:\n",
    "                new_likes = container.findAll(\"li\", {\"class\":\"social-details-social-counts__reactions social-details-social-counts__item\"})\n",
    "                new_comments = container.findAll(\"li\", {\"class\": \"social-details-social-counts__comments social-details-social-counts__item\"})\n",
    "            except:\n",
    "                new_likes = 'none'\n",
    "                new_comments = \"none\"\n",
    "\n",
    "            try:\n",
    "                video_box = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__content feed-shared-linkedin-video ember-view\"})\n",
    "                video_link = video_box[0].find(\"video\", {\"class\":\"vjs-tech\"})\n",
    "                media_links.append(video_link['src'])\n",
    "                media_type.append(\"Video\")\n",
    "            except:\n",
    "                try:\n",
    "                    image_box = container.findAll(\"div\",{\"class\": \"feed-shared-image__container\"})\n",
    "                    image_link = image_box[0].find(\"img\", {\"class\":\"ivm-view-attr__img--centered feed-shared-image__image feed-shared-image__image--constrained lazy-image ember-view\"})\n",
    "                    media_links.append(image_link['src'])\n",
    "                    media_type.append(\"Image\")\n",
    "                except:\n",
    "                    try:\n",
    "                        #mutiple shared images\n",
    "                        image_box = container.findAll(\"div\",{\"class\": \"feed-shared-image__container\"})\n",
    "                        image_link = image_box[0].find(\"img\", {\"class\":\"ivm-view-attr__img--centered feed-shared-image__image lazy-image ember-view\"})\n",
    "                        media_links.append(image_link['src'])\n",
    "                        media_type.append(\"Multiple Images\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            article_box = container.findAll(\"div\",{\"class\": \"feed-shared-article__description-container\"})\n",
    "                            article_link = article_box[0].find('a', href=True)\n",
    "                            media_links.append(article_link['href'])\n",
    "                            media_type.append(\"Article\")\n",
    "                        except:\n",
    "                            try:\n",
    "                                video_box = container.findAll(\"div\",{\"class\": \"feed-shared-external-video__meta\"})          \n",
    "                                video_link = video_box[0].find('a', href=True)\n",
    "                                media_links.append(video_link['href'])\n",
    "                                media_type.append(\"Youtube Video\")   \n",
    "                            except:\n",
    "                                try:\n",
    "                                    poll_box = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__content overflow-hidden feed-shared-poll ember-view\"})\n",
    "                                    media_links.append(\"None\")\n",
    "                                    media_type.append(\"Other: Poll, Shared Post, etc\")\n",
    "                                except:\n",
    "                                    media_links.append(\"None\")\n",
    "                                    media_type.append(\"Unknown\")\n",
    "\n",
    "\n",
    "\n",
    "            #Getting Video Views. (The folling three lines prevents class name overlap)\n",
    "            view_container2 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__item\"]}))\n",
    "            view_container1 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__reactions\",\"social-details-social-counts__comments social-details-social-counts__item\"]}))\n",
    "            result = view_container2 - view_container1\n",
    "\n",
    "            view_container = []\n",
    "            for i in result:\n",
    "                view_container += i\n",
    "\n",
    "            try:\n",
    "                video_views.append(view_container[1].text.strip().replace(' Views',''))\n",
    "\n",
    "            except:\n",
    "                video_views.append('N/A')\n",
    "\n",
    "\n",
    "            try:\n",
    "                post_likes.append(new_likes[0].text.strip())\n",
    "            except:\n",
    "                post_likes.append(0)\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                post_comments.append(new_comments[0].text.strip())                           \n",
    "            except:                                                           \n",
    "                post_comments.append(0)\n",
    "                pass\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_dates = []\n",
    "# post_texts = []\n",
    "# post_likes = []\n",
    "# post_comments = []\n",
    "# video_views = []\n",
    "# media_links = []\n",
    "# media_type = []\n",
    "\n",
    "# browser.switch_to.window(browser.window_handles[1])\n",
    "# post_source = get_source()\n",
    "# containers = post_source.findAll(\"div\",{\"class\":\"feed-shared-update-v2 feed-shared-update-v2--minimal-padding full-height relative artdeco-card ember-view\"})\n",
    "# container = containers[0]\n",
    "\n",
    "\n",
    "\n",
    "# try:\n",
    "#     try:\n",
    "#         post_date = container.find(\"span\",{\"class\":\"feed-shared-actor__sub-description t-12 t-normal t-black--light\"}) \n",
    "#         post_dates.append(post_date.text.strip()[0:-2])\n",
    "#     except:\n",
    "#         post_dates.append(\"None\")\n",
    "\n",
    "#     try:\n",
    "#         text_box = container.find(\"span\",{\"class\":\"entity-result__summary entity-result__no-ellipsis mt3 t-14 t-black\"})\n",
    "#         if text_box == None:\n",
    "#             text_box = container.find(\"p\",{\"class\":\"entity-result__content-summary entity-result__no-ellipsis t-14\"}) \n",
    "\n",
    "#         post_texts.append(text_box.text.strip())\n",
    "\n",
    "#     except:\n",
    "#         post_texts.append(\"None\")\n",
    "\n",
    "#     try:\n",
    "#         new_likes = container.findAll(\"li\", {\"class\":\"social-details-social-counts__reactions social-details-social-counts__item\"})\n",
    "#         new_comments = container.findAll(\"li\", {\"class\": \"social-details-social-counts__comments social-details-social-counts__item\"})\n",
    "#     except:\n",
    "#         new_likes = 'none'\n",
    "#         new_comments = \"none\"\n",
    "\n",
    "#     try:\n",
    "#         video_box = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__content feed-shared-linkedin-video ember-view\"})\n",
    "#         video_link = video_box[0].find(\"video\", {\"class\":\"vjs-tech\"})\n",
    "#         media_links.append(video_link['src'])\n",
    "#         media_type.append(\"Video\")\n",
    "#     except:\n",
    "#         try:\n",
    "#             image_box = container.findAll(\"div\",{\"class\": \"feed-shared-image__container\"})\n",
    "#             image_link = image_box[0].find(\"img\", {\"class\":\"ivm-view-attr__img--centered feed-shared-image__image feed-shared-image__image--constrained lazy-image ember-view\"})\n",
    "#             media_links.append(image_link['src'])\n",
    "#             media_type.append(\"Image\")\n",
    "#         except:\n",
    "#             try:\n",
    "#                 #mutiple shared images\n",
    "#                 image_box = container.findAll(\"div\",{\"class\": \"feed-shared-image__container\"})\n",
    "#                 image_link = image_box[0].find(\"img\", {\"class\":\"ivm-view-attr__img--centered feed-shared-image__image lazy-image ember-view\"})\n",
    "#                 media_links.append(image_link['src'])\n",
    "#                 media_type.append(\"Multiple Images\")\n",
    "#             except:\n",
    "#                 try:\n",
    "#                     article_box = container.findAll(\"div\",{\"class\": \"feed-shared-article__description-container\"})\n",
    "#                     article_link = article_box[0].find('a', href=True)\n",
    "#                     media_links.append(article_link['href'])\n",
    "#                     media_type.append(\"Article\")\n",
    "#                 except:\n",
    "#                     try:\n",
    "#                         video_box = container.findAll(\"div\",{\"class\": \"feed-shared-external-video__meta\"})          \n",
    "#                         video_link = video_box[0].find('a', href=True)\n",
    "#                         media_links.append(video_link['href'])\n",
    "#                         media_type.append(\"Youtube Video\")   \n",
    "#                     except:\n",
    "#                         try:\n",
    "#                             poll_box = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__content overflow-hidden feed-shared-poll ember-view\"})\n",
    "#                             media_links.append(\"None\")\n",
    "#                             media_type.append(\"Other: Poll, Shared Post, etc\")\n",
    "#                         except:\n",
    "#                             media_links.append(\"None\")\n",
    "#                             media_type.append(\"Unknown\")\n",
    "\n",
    "\n",
    "\n",
    "#     #Getting Video Views. (The folling three lines prevents class name overlap)\n",
    "#     view_container2 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__item\"]}))\n",
    "#     view_container1 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__reactions\",\"social-details-social-counts__comments social-details-social-counts__item\"]}))\n",
    "#     result = view_container2 - view_container1\n",
    "\n",
    "#     view_container = []\n",
    "#     for i in result:\n",
    "#         view_container += i\n",
    "\n",
    "#     try:\n",
    "#         video_views.append(view_container[1].text.strip().replace(' Views',''))\n",
    "\n",
    "#     except:\n",
    "#         video_views.append('N/A')\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         post_likes.append(new_likes[0].text.strip())\n",
    "#     except:\n",
    "#         post_likes.append(0)\n",
    "#         pass\n",
    "\n",
    "#     try:\n",
    "#         post_comments.append(new_comments[0].text.strip())                           \n",
    "#     except:                                                           \n",
    "#         post_comments.append(0)\n",
    "#         pass\n",
    "\n",
    "# except:\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source():  \n",
    "    company_page = browser.page_source\n",
    "    linkedin_soup = bs(company_page.encode(\"utf-8\"), \"html\")\n",
    "    #linkedin_soup.prettify()\n",
    "\n",
    "    return linkedin_soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_posts(links):\n",
    "    \n",
    "    for link in links:\n",
    "\n",
    "        link.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        #switch to post page and get source\n",
    "        browser.switch_to.window(browser.window_handles[1])\n",
    "        post_source = get_source()\n",
    "        \n",
    "        \n",
    "        post_block = post_source.findAll(\"div\",{\"class\":\"core-rail update-outlet\"})\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #scrape the post and then close and switch back to main page\n",
    "        scrape_post(post_block[0])\n",
    "        browser.close()\n",
    "        browser.switch_to.window(browser.window_handles[0])\n",
    "        time.sleep(random.randint(4,24))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_links():\n",
    "    #scroll to end of list\n",
    "    scroll()\n",
    "    links = []\n",
    "    hrefs = []\n",
    "    \n",
    "    #find all post links\n",
    "    elems = browser.find_elements_by_xpath(\"//a[@href]\")\n",
    "    for elem in elems:\n",
    "        #check if the link is a feed\n",
    "        if 'https://www.linkedin.com/feed/update/' in elem.get_attribute('href'): \n",
    "            links.append(elem)\n",
    "            hrefs.append(elem.get_attribute('href'))\n",
    "        \n",
    "        \n",
    "    scroll_up()\n",
    "    return links, hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_links(links, hrefs):\n",
    "    mask = [True]\n",
    "    \n",
    "    for idx, link in enumerate(hrefs[1:], 1):\n",
    "        if link == hrefs[idx-1]:\n",
    "            mask.append(False)\n",
    "        else:\n",
    "            mask.append(True)\n",
    "            \n",
    "    unique_links = [elem for bol,elem in zip(mask, links) if bol]\n",
    "    \n",
    "    return unique_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dates = []\n",
    "post_texts = []\n",
    "post_likes = []\n",
    "post_comments = []\n",
    "video_views = []\n",
    "media_links = []\n",
    "media_type = []\n",
    "\n",
    "def scrape_pages():\n",
    "    page = 1\n",
    "    page_limit = 10\n",
    "    \n",
    "    while page < page_limit:\n",
    "\n",
    "        links, hrefs = get_post_links()\n",
    "        #print('links:\\n',links)\n",
    "        \n",
    "        unique_links = get_unique_links(links, hrefs)\n",
    "\n",
    "        get_posts(unique_links)\n",
    "        #print('post_dates:\\n',post_dates)\n",
    "        \n",
    "        try:\n",
    "            browser.find_element_by_xpath('//*[@class=\"artdeco-pagination__button artdeco-pagination__button--next artdeco-button artdeco-button--muted artdeco-button--icon-right artdeco-button--1 artdeco-button--tertiary ember-view\"]').click()\n",
    "            time.sleep(random.randint(1,5))\n",
    "            page += 1\n",
    "        except:\n",
    "            print(\"All pages scraped\")\n",
    "            break   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dates = []\n",
    "\n",
    "for i in post_dates:\n",
    "    d = str(i[0:3]).replace('\\n\\n', '').replace('â€¢','').replace(' ', '')\n",
    "    cleaned_dates += [d]\n",
    "    \n",
    "# comment_count = []\n",
    "# for i in post_comments:\n",
    "#     s = str(i).replace('Comment','').replace('s','').replace(' ','')\n",
    "#     comment_count += [s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('max_colwidth', 1000)\n",
    "\n",
    "data = {\n",
    "    \"Date Posted\": cleaned_dates,\n",
    "    \"Media Type\": media_type,\n",
    "    \"Post Text\": post_texts,\n",
    "    \"Post Likes\": post_likes,\n",
    "    \"Post Comments\": post_comments,\n",
    "    \"Video Views\": video_views,\n",
    "    \"Media Links\": media_links\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write original dataframe to excel file\n",
    "#df.to_csv(\"{}_posts.csv\".format(company_name), encoding='utf-8', index=False)\n",
    "\n",
    "writer = pd.ExcelWriter(\"{}_posts.xlsx\".format('#affordablehousing'), engine='xlsxwriter')\n",
    "df.to_excel(writer, index =False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write unique dataframe to csv file\n",
    "unique_df.to_csv('gross_linkedin_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
