PAGE:  108
Traceback (most recent call last):
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connection.py", line 156, in _new_conn
    conn = connection.create_connection(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\util\connection.py", line 84, in create_connection
    raise err
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\util\connection.py", line 74, in create_connection
    sock.connect(sa)
OSError: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connectionpool.py", line 665, in urlopen        
    httplib_response = self._make_request(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request  
    conn.request(method, url, **httplib_request_kw)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\http\client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked) 
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\http\client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\http\client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked) 
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\http\client.py", line 1007, in _send_output
    self.send(msg)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\http\client.py", line 947, in send
    self.connect()
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000242CD7F1430>: Failed to establish a new connection: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "data_collection\Local News\Vanguard\scrape_catalog.py", line 76, in <module>
    LINK = str(element.get_attribute('href'))
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\webelement.py", line 139, in get_attribute
    attributeValue = self.parent.execute_script(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 634, in execute_script
    return self.execute(command, {
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 402, in _request
    resp = http.request(method, url, body=body, headers=headers)   
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\request.py", line 79, in request
    return self.request_encode_body(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\request.py", line 171, in request_encode_body   
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\poolmanager.py", line 330, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connectionpool.py", line 747, in urlopen        
    return self.urlopen(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connectionpool.py", line 747, in urlopen        
    return self.urlopen(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connectionpool.py", line 747, in urlopen        
    return self.urlopen(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\connectionpool.py", line 719, in urlopen        
    retries = retries.increment(
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause)) 
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=54003): Max retries exceeded with url: /session/6d5abb8515403e2bb7d021eac7448890/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000242CD7F1430>: Failed to establish a new connection: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted'))
Initiating Scraping. 
Scrapping:
Page: base PAGE
PAGE:  1
PAGE:  2
Traceback (most recent call last):
  File "data_collection\Local News\Vanguard\scrape_catalog.py", line 88, in <module>
    button = buttons[-1].click()
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\webelement.py", line 80, in click
    self._execute(Command.CLICK_ELEMENT)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "C:\Users\rohaan.nadeem\Anaconda3\envs\Web Scrapping\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout: Timed out receiving message from renderer: 30.000
  (Session info: chrome=91.0.4472.114)